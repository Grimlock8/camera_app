
<html lang=”en”>
	<head>
		<meta charset="utf-8">
		<meta http-equiv="x-ua-compatible" content="ie=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

		<!-- Name of the app -->
		<title>Camera App</title>

		<!-- Link to main style sheet -->
		<link rel="stylesheet" href="style.css"> 
	</head>
	<body>

		<!-- Camera -->
		<main id="camera">

		    <!-- Camera sensor -->
		    <canvas id="camera--sensor"></canvas>
		    
		    <!-- Camera view -->
		    <video id="camera--view" autoplay playsinline></video>
		    
		    <!-- Camera output -->
		    <img src="//:0" alt="" id="camera--output">

		    <!-- Camera trigger -->
		    <button id="camera--trigger">Take a picture</button>

		</main>

		<!-- Reference to your JavaScript file -->
		<script src="app.js"></script> 
	</body>
</html>

<script>
// Set constraints for the video stream
var constraints = { video: { facingMode: "user" }, audio: false };
var track = null;

// Define constants
const cameraView = document.querySelector("#camera--view"),
    cameraOutput = document.querySelector("#camera--output"),
    cameraSensor = document.querySelector("#camera--sensor"),
    cameraTrigger = document.querySelector("#camera--trigger");

// Access the device camera and stream to cameraView
function cameraStart() {
    navigator.mediaDevices
        .getUserMedia(constraints)
        .then(function(stream) {
            track = stream.getTracks()[0];
            cameraView.srcObject = stream;
        })
        .catch(function(error) {
            console.error("Oops. Something is broken.", error);
        });
}

// Take a picture when cameraTrigger is tapped
cameraTrigger.onclick = function() {
    cameraSensor.width = cameraView.videoWidth;
    cameraSensor.height = cameraView.videoHeight;
    cameraSensor.getContext("2d").drawImage(cameraView, 0, 0);
    cameraOutput.src = cameraSensor.toDataURL("image/webp");
    cameraOutput.classList.add("taken");
    // track.stop();
};

// Start the video stream when the window loads
window.addEventListener("load", cameraStart, false);
    
    
/*    
    
@*
    For more information on enabling MVC for empty projects, visit https://go.microsoft.com/fwlink/?LinkID=397860
*@
@{
}
@{
    ViewData["Title"] = "Camera Page";
}

<video id="camera--view" autoplay playsinline></video>
<p> <canvas id="canvas"></canvas> </p>
<button id="start-button" onclick="startFunction()">Grab one frame</button>
<button onclick="invert()">Invert grabbed frame</button>

        <a id="downloadPhoto" download="my-photo.jpg" class="button" role="button">Download</a>

<script>
const 
    cameraSensor = document.querySelector("#canvas"),
    downloadTrigger = document.querySelector("#downloadPhoto");
//const constraints = { "video": { width: { max: 320 } } };
    var constraints = { 
    video: { 
        facingMode: {exact: "user" },   
        //facingMode: {exact: "environment" }, 
            width: { ideal: 1920 },
            height: { ideal: 1080 },
            frameRate: {
                ideal: 60,
                min: 10
            }
    }, 
    audio: false 
};
    
// Define constants
const cameraView = document.querySelector("#camera--view");

// Access the device camera and stream to cameraView
function cameraStart() {
    navigator.mediaDevices
        .getUserMedia(constraints)
        .then(function(stream) {
            track = stream.getTracks()[0];
            cameraView.srcObject = stream;
        })
        .catch(function(error) {
            console.error("Oops. Something is broken.", error);
        });
}    
    
var canvas = document.getElementById('canvas');
var videoTrack;

function startFunction() {
  navigator.mediaDevices.getUserMedia(constraints)
      .then(gotMedia)
      .catch(e => { console.error('getUserMedia() failed: ', e); });
}

function gotMedia(mediastream) {
  videoTrack = mediastream.getVideoTracks()[0];
  var imageCapture = new ImageCapture(videoTrack);
  imageCapture.grabFrame()
      .then(processFrame)
      .catch(e => console.error('grabFrame() failed: ' + e));
}

function processFrame(imageBitmap) {
  canvas.width = imageBitmap.width;
  canvas.height = imageBitmap.height;
  canvas.getContext('2d').drawImage(imageBitmap, 0, 0);

  videoTrack.stop();
}

function invert() {
  var ctx = canvas.getContext('2d');
  var imageData = ctx.getImageData(0,0,canvas.width, canvas.height);

  var data = imageData.data;
  for (var i = 0; i < data.length; i += 4) {
    data[i]     = 255 - data[i];     // red
    data[i + 1] = 255 - data[i + 1]; // green
    data[i + 2] = 255 - data[i + 2]; // blue
  }
  ctx.putImageData(imageData, 0, 0);
}

downloadTrigger.onclick = function() {
    const canvas = cameraSensor.toDataURL("image/jpeg")
    .replace("image/jpeg", "image/octet-stream");    
    downloadTrigger.setAttribute("href", canvas);
};
    
// Start the video stream when the window loads
window.addEventListener("load", cameraStart, false);    

/*<span class="error"></span>
<br>
<label for="interval">Time between images in seconds: </label>
<input id="interval" type="text" value="1" min="1" pattern="\d+">
<br>
<button id="start">Start</button>
<br>
<label for="hideVid">Hide video element: </label>
<input id="hideVid" type="checkbox">
<br>
<p>Camera Settings</p>
<span id="settings"></span>
<p>Camera capabilities</p>
<span id="caps"></span>
<br>
<video autoplay muted playsinline></video>
<p>
  Images captured: <span id="image_count">0</span>
</p>
<br>
<button id="stop" disabled>Stop & Show Images</button>
<div id="images"></div>


       // check for support
    if(typeof ImageCapture === 'undefined'){
        const supportError = "ImageCapture is not supported by your browser";
        const errorSpan = document.querySelector('span.error');
        errorSpan.style = "color:red;font-size:larger;font-weight:bold";
        errorSpan.innerText = supportError;
        console.error(supportError);
    }

    const startBtn = document.querySelector('button#start');
    const stopBtn = document.querySelector('button#stop');
    const hideVid = document.querySelector('input#hideVid')
    const intervalSec = document.querySelector('input#interval');
    const videoElem = document.querySelector('video');
    const imageCountSpan = document.querySelector('span#image_count');
    const settingsSpan = document.querySelector('span#settings');
    const capsSpan = document.querySelector('span#caps');
    const imagesDiv = document.querySelector('div#images');
    const storage = [];     // Use this array as our database
    let stream, captureInterval;

    hideVid.onclick = () => videoElem.hidden = hideVid.checked;


    startBtn.onclick = async () => {
        startBtn.disabled = true;

        stream = await navigator.mediaDevices.getUserMedia({video: true});
        videoElem.onplaying = () => console.log("video playing stream:", videoElem.srcObject);
        videoElem.srcObject = stream;

        const [track] = stream.getVideoTracks();
        const imageCapture = new ImageCapture(track);
        const photoCapabilities = await imageCapture.getPhotoCapabilities();
        capsSpan.innerText = JSON.stringify(photoCapabilities);
        console.log("Photo Capabilities: ", photoCapabilities);
        const photoSettings = await imageCapture.getPhotoSettings();
        settingsSpan.innerText = JSON.stringify(photoSettings);
        console.log("Photo settings: ", photoSettings);

        // (data check on the interval value) * that value is in seconds  * frame timestamps are in microseconds
        const interval = (parseInt(intervalSec.value) >= 1 ? intervalSec.value * 1 : 1) * 1000;
        captureInterval = setInterval(async () => {
            const blob = await imageCapture.takePhoto()
                .catch(err => console.error(err)); // It took a few seconds for me the camera to get ready

            if(blob){
                console.log(blob);
                storage.push(blob);
                imageCountSpan.innerText++;
            }

        }, interval);

        stopBtn.disabled = false;
    }

    stopBtn.onclick = () => {
        // stop capture
        clearInterval(captureInterval);

        // close the camera
        stream.getTracks().forEach(track => track.stop());

        // Display each image
        function showImages() {
            const blob = storage.shift();
            const imageUrl = URL.createObjectURL(blob);
            const imgElem = new Image();
            imgElem.src = imageUrl;
            imagesDiv.appendChild(imgElem);

            if (storage.length > 0)
                showImages();
        }

        console.log("stored images");
        showImages();
    }
    
    .view-area {
    background-color:aqua;
    width: 500px !important;
    height: 300px !important;
}
#camera, #camera--view, #camera--sensor, #camera--output{
    position: fixed;
    height: 50%;
    width: 50%;
    object-fit: cover;
}

/* This can be deleted or commented out when the final app
    is ready to go.  It is only useful for the User facing
    Camera.
*/
/*#camera--view, #camera--sensor, #camera--output{
    transform: scaleX(-1);
    filter: FlipH;
}

#start-button{
    width: 200px;
    background-color: black;
    color: white;
    font-size: 16px;
    border-radius: 30px;
    border: none;
    padding: 15px 20px;
    text-align: center;
    box-shadow: 0 5px 10px 0 rgba(0,0,0,0.2);
    position: fixed;
    bottom: 120px;
    left: calc(50% - 100px);
}

#downloadPhoto{
    width: 200px;
    background-color: black;
    color: white;
    font-size: 16px;
    border-radius: 30px;
    border: none;
    padding: 15px 20px;
    text-align: center;
    box-shadow: 0 5px 10px 0 rgba(0,0,0,0.2);
    position: fixed;
    bottom: 60px;
    left: calc(50% - 119px);
}

.taken{
    height: 100px!important;
    width: 100px!important;
    transition: all 0.5s ease-in;
    border: solid 3px white;
    box-shadow: 0 5px 10px 0 rgba(0,0,0,0.2);
    top: 20px;
    right: 20px;
    z-index: 2;
}
    
    */
</script>

        <style>


            html, body{
  margin: 0;
  padding: 0;
  height: 100%;
  width: 100%;
}

#camera, #camera--view, #camera--sensor, #camera--output{
    position: fixed;
    height: 100%;
    width: 100%;
    object-fit: cover;
}

#camera--view, #camera--sensor, #camera--output{
    transform: scaleX(-1);
    filter: FlipH;
}

#camera--trigger{
    width: 200px;
    background-color: black;
    color: white;
    font-size: 16px;
    border-radius: 30px;
    border: none;
    padding: 15px 20px;
    text-align: center;
    box-shadow: 0 5px 10px 0 rgba(0,0,0,0.2);
    position: fixed;
    bottom: 30px;
    left: calc(50% - 100px);
}

.taken{
    height: 100px!important;
    width: 100px!important;
    transition: all 0.5s ease-in;
    border: solid 3px white;
    box-shadow: 0 5px 10px 0 rgba(0,0,0,0.2);
    top: 20px;
    right: 20px;
    z-index: 2;
}
Footer
© 2022 GitHub, Inc.
Footer navigation
Terms
Privacy
Security
S
</style>
